{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "layout: post\n",
    "title: Computer Bias\n",
    "description: Computer Bias\n",
    "type: issues\n",
    "comments: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Popcorn Hack #1\n",
    "Question: Describe the biased system, explain what type of bias it represents (Pre-existing Social Bias, Technical Bias, or Emergent Social Bias), and suggest one way to reduce or fix the bias.\n",
    "\n",
    "- In the criminal justice system, for crime prediction or adjacent computational tasks, there are algorithms that predict the likelihood of a person committing a crime based on their past behavior and other factors. These algorithms can be biased against african-american individuals, as historically socioceconomic bias in the past means a lot of convicts are african-american thus computer systems bias against them.\n",
    "- This is **pre-existing bias** as the data skews heavily towards criminals being African-Americans, thus this is a pre-existing social bias that the system is propagating.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack #2\n",
    "\n",
    "- One way is to skew the data set using specifically resampling, to prevent data imbalances (undersampling, oversampling could use algorithms like SMOTE)\n",
    "- Another way is to increase the amount of data, which can proivde more data samples and potentially reduce bias, but in general data imbalances can still lead to the model being biased.\n",
    "- In general, other ways could be to remove features that are based on pre-existing social bias in the mdoel training. So removing, features such as gender or race that have pre-existing social biases to reduce algorithmic bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Homework Hack\n",
    "System: Google Maps Recommendation Systems, based on where I have been in the past it recommends places to eat.\n",
    "Bias: This is algorithmic bias, as the system only recommends places based on where I have been and this is algorithmic bias as the algorithm dictates future results based on the data from past searchse which is bias.\n",
    "Propose One Way: In this case this isn't necessarily bad, a recommendation is a system of bias technically but it isn't negative in some scenarios such as this one the recommendation is beneficial to the user. But if we didn't want this system, we could have the algorithm use random selection based on a dataset of good restaurants or something. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
